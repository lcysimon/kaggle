{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "from pandas import *\n",
    "import numpy\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize values\n",
    "\n",
    "env = None\n",
    "sample_size = None\n",
    "# Set env, if env = test, will only be run locally and display the result\n",
    "env = \"prod\"\n",
    "env = \"test\"\n",
    "\n",
    "nb_models = 10\n",
    "nb_min_value_before = 0\n",
    "nb_min_value_after = 50\n",
    "\n",
    "# Number of value on which to train, if null, train on all value\n",
    "sample_size = None\n",
    "test_size = 1000\n",
    "\n",
    "# if set to true, we will delete variable on the way, might be useful for retry\n",
    "os.environ['gc'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete an object and call garbage collection just after, to be extra safe\n",
    "def del_object(object):\n",
    "    if os.environ['gc'] == 'true':\n",
    "        del(object)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_data contais cuisine        39774\n",
      "id             39774\n",
      "ingredients    39774\n",
      "dtype: int64 elements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...\n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...\n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35203</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17600</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  cuisine\n",
       "0  35203  italian\n",
       "1  17600  italian"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read training data + test data\n",
    "df_data = pandas.read_json(\"../input/train.json\")\n",
    "df_test = pandas.read_json(\"../input/test.json\")\n",
    "df_sample_input = pandas.read_csv(\"../input/sample_submission.csv\")\n",
    "\n",
    "print(\"df_data contais {0} elements\".format(df_data.count()))\n",
    "# Display basic information\n",
    "display(df_data.head(3))\n",
    "display(df_test.head(3))\n",
    "display(df_sample_input.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_data_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1814a21fa3f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdf_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df_data contais {0} elements\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1814a21fa3f1>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(df_data, df_test, env)\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_data_input' is not defined"
     ]
    }
   ],
   "source": [
    "def get_data(df_data, df_test, env):\n",
    "    if env == \"test\":\n",
    "        if sample_size is not None and sample_size > 0:\n",
    "            df_data = df_data.sample(sample_size)\n",
    "        else:\n",
    "            df_data = df_data_input\n",
    "        df_test = df_data.sample(test_size)\n",
    "\n",
    "        # Removing all df_test from df_data to ensure not train with test data\n",
    "        df_common = df_data.merge(df_test,on=['id'])\n",
    "        #display(df_common)\n",
    "        df_data = df_data[(~df_data.id.isin(df_common.id))]\n",
    "        del(df_common)\n",
    "    else:\n",
    "        # set that to some default value\n",
    "        df_test = df_test_input\n",
    "        df_test['cuisine'] = \"todo\"\n",
    "        if sample_size is not None and sample_size > 0:\n",
    "            df_data = df_data_input.sample(sample_size)\n",
    "        else:\n",
    "            df_data = df_data_input\n",
    "    return df_data, df_test\n",
    "\n",
    "df_data, df_test = get_data(df_data, df_test, env)\n",
    "        \n",
    "print(\"df_data contais {0} elements\".format(df_data.count()))\n",
    "# Display basic information\n",
    "display(df_data.head(3))\n",
    "display(df_test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count1: 38774\n",
      "count2: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'N</th>\n",
       "      <th>'n</th>\n",
       "      <th>(</th>\n",
       "      <th>(10</th>\n",
       "      <th>(14</th>\n",
       "      <th>(14.5</th>\n",
       "      <th>(15</th>\n",
       "      <th>...</th>\n",
       "      <th>yum</th>\n",
       "      <th>yuzu</th>\n",
       "      <th>za'atar</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zinfandel</th>\n",
       "      <th>ziti</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>épices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3591 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id    &   'N   'n    (  (10  (14  (14.5  (15   ...    yum  \\\n",
       "0        greek  10259  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0   ...    0.0   \n",
       "1  southern_us  25693  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0   ...    0.0   \n",
       "2     filipino  20130  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0   ...    0.0   \n",
       "3       indian  22213  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0   ...    0.0   \n",
       "4       indian  13162  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0   ...    0.0   \n",
       "\n",
       "   yuzu  za'atar  zero  zest  zesty  zinfandel  ziti  zucchini  épices  \n",
       "0   0.0      0.0   0.0   0.0    0.0        0.0   0.0       0.0     0.0  \n",
       "1   0.0      0.0   0.0   0.0    0.0        0.0   0.0       0.0     0.0  \n",
       "2   0.0      0.0   0.0   0.0    0.0        0.0   0.0       0.0     0.0  \n",
       "3   0.0      0.0   0.0   0.0    0.0        0.0   0.0       0.0     0.0  \n",
       "4   0.0      0.0   0.0   0.0    0.0        0.0   0.0       0.0     0.0  \n",
       "\n",
       "[5 rows x 3591 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract columns values of ingredients to multiple columns with boolean\n",
    "import re\n",
    "\n",
    "def process_value(myValue):\n",
    "    return lower(myValue)\n",
    "    \n",
    "def preprocess_dataframe(df1, df2):\n",
    "    count1 = len(df1)\n",
    "    count2 = len(df2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"count1: {0}\".format(count1))\n",
    "    print(\"count2: {0}\".format(count2))\n",
    "    \n",
    "    total_df = df1.append(df2, ignore_index=True)\n",
    "    \n",
    "    d_list = []\n",
    "    \n",
    "    output = []\n",
    "    all_ingredients = {}\n",
    "    for index, row in total_df.iterrows():\n",
    "        for value_field in row['ingredients']:\n",
    "            # Transform the value to remove number and percentage\n",
    "            values = re.split('\\s+', value_field)\n",
    "            for value in values:\n",
    "                # build a dictionnary of all values\n",
    "                if value not in output:\n",
    "                    output.append(value)\n",
    "                    all_ingredients[value] = 1\n",
    "                else:\n",
    "                    all_ingredients[value] += 1\n",
    "                d_list.append({'id':row['id'], \n",
    "                               'value':value})\n",
    "\n",
    "    total_df = total_df.append(d_list, ignore_index=True)\n",
    "    total_df = total_df.groupby('id')['value'].value_counts()\n",
    "    total_df = total_df.unstack(level=-1).fillna(0)\n",
    "        \n",
    "    \n",
    "    # Then, we need to merge df_1 and df_2 with their id\n",
    "    df1 = df1.merge(total_df, left_on='id', right_on='id', how='inner')\n",
    "    df2 = df2.merge(total_df, left_on='id', right_on='id', how='inner')\n",
    "    \n",
    "    del(total_df)\n",
    "\n",
    "    # We do not need the ingredients column now, so, we can remove it\n",
    "    df1 = df1.drop(columns=['ingredients'])\n",
    "    df2 = df2.drop(columns=['ingredients'])\n",
    "\n",
    "    return df1, df2, all_ingredients\n",
    "\n",
    "df_data_0, df_test_0, all_ingredients = preprocess_dataframe(df_data, df_test)\n",
    "\n",
    "\n",
    "\n",
    "def category_to_number(df):\n",
    "    df[\"code_cuisine\"] = df.cuisine.astype(\"category\").cat.codes\n",
    "    mapping = df[[\"cuisine\", \"code_cuisine\"]]\n",
    "    return df, mapping.drop_duplicates()\n",
    "\n",
    "#df_data_1, code_mapping = category_to_number(df_data_1)\n",
    "#df_test_1, empty = category_to_number(df_test_1)\n",
    "\n",
    "\n",
    "display(df_data.head(5))\n",
    "display(df_data_0.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'N</th>\n",
       "      <th>'n</th>\n",
       "      <th>(</th>\n",
       "      <th>(10</th>\n",
       "      <th>(14</th>\n",
       "      <th>(14.5</th>\n",
       "      <th>(15</th>\n",
       "      <th>...</th>\n",
       "      <th>yum</th>\n",
       "      <th>yuzu</th>\n",
       "      <th>za'atar</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zinfandel</th>\n",
       "      <th>ziti</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>épices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>15906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>42271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexican</td>\n",
       "      <td>34692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexican</td>\n",
       "      <td>28301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>italian</td>\n",
       "      <td>17392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3591 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id    &   'N   'n    (  (10  (14  (14.5  (15   ...    yum  \\\n",
       "0  southern_us  15906  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0   ...    0.0   \n",
       "1  southern_us  42271  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0   ...    0.0   \n",
       "2      mexican  34692  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0   ...    0.0   \n",
       "3      mexican  28301  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0   ...    0.0   \n",
       "4      italian  17392  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0   ...    0.0   \n",
       "\n",
       "   yuzu  za'atar  zero  zest  zesty  zinfandel  ziti  zucchini  épices  \n",
       "0   0.0      0.0   0.0   0.0    0.0        0.0   0.0       0.0     0.0  \n",
       "1   0.0      0.0   0.0   0.0    0.0        0.0   0.0       0.0     0.0  \n",
       "2   0.0      0.0   0.0   0.0    0.0        0.0   0.0       0.0     0.0  \n",
       "3   0.0      0.0   0.0   0.0    0.0        0.0   0.0       0.0     0.0  \n",
       "4   0.0      0.0   0.0   0.0    0.0        0.0   0.0       0.0     0.0  \n",
       "\n",
       "[5 rows x 3591 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check dictionnary and create df_data_1 and df_test_1 from it\n",
    "output = {}\n",
    "for key, value in all_ingredients.items():\n",
    "    if value not in output:\n",
    "        output[value] = [key]\n",
    "    else:\n",
    "        output[value].append(key)\n",
    "#print(output)\n",
    "\n",
    "# Shuffle the data as well\n",
    "#df = df.sample(frac=1).reset_index(drop=True)\n",
    "df_data_1 = df_data_0.sample(frac=1).reset_index(drop=True)\n",
    "df_test_1 = df_test_0\n",
    "\n",
    "#print(output)\n",
    "to_remove = []\n",
    "for key, values in output.items():\n",
    "    for value in values:\n",
    "        if key < nb_min_value_before:\n",
    "            #print(\"Removing {0}\".format(value))\n",
    "            to_remove.append(value)\n",
    "df_data_1 = df_data_1.drop(columns=to_remove)\n",
    "df_test_1 = df_test_1.drop(columns=to_remove)\n",
    "\n",
    "#TODO multiply the training data by cuisine type as well\n",
    "\n",
    "display(df_data_1.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value per cuisine = 7637\n",
      "Got 4207 value for southern_us, need to add 3430\n",
      "Append a dataframe of 4207 values\n",
      "Got 6272 value for mexican, need to add 1365\n",
      "Append a dataframe of 6272 values\n",
      "Got 7637 value for italian, need to add 0\n",
      "Got 2604 value for chinese, need to add 5033\n",
      "Append a dataframe of 5033 values\n",
      "Got 654 value for irish, need to add 6983\n",
      "Append a dataframe of 6983 values\n",
      "Got 798 value for moroccan, need to add 6839\n",
      "Append a dataframe of 6839 values\n",
      "Got 2580 value for french, need to add 5057\n",
      "Append a dataframe of 5057 values\n",
      "Got 1389 value for japanese, need to add 6248\n",
      "Append a dataframe of 6248 values\n",
      "Got 2939 value for indian, need to add 4698\n",
      "Append a dataframe of 4698 values\n",
      "Got 455 value for brazilian, need to add 7182\n",
      "Append a dataframe of 7182 values\n",
      "Got 805 value for vietnamese, need to add 6832\n",
      "Append a dataframe of 6832 values\n",
      "Got 1501 value for thai, need to add 6136\n",
      "Append a dataframe of 6136 values\n",
      "Got 476 value for russian, need to add 7161\n",
      "Append a dataframe of 7161 values\n",
      "Got 1148 value for greek, need to add 6489\n",
      "Append a dataframe of 6489 values\n",
      "Got 512 value for jamaican, need to add 7125\n"
     ]
    }
   ],
   "source": [
    "# Multiply the training data set for food where there is not that much data\n",
    "df_count = df_data_1.groupby('cuisine')['cuisine']\n",
    "max_recipe_count_per_cuisine = df_count.count().max()\n",
    "# Loop over all cuisine, if while < minimal, add this dataframe, then add a sample of those, to get exactly the same number\n",
    "\n",
    "print(\"Max value per cuisine = {0}\".format(max_recipe_count_per_cuisine))\n",
    "df_data_2 = df_data_1\n",
    "df_test_2 = df_test_1\n",
    "del(df_data_1)\n",
    "del(df_test_1)\n",
    "for cuisine in df_data_2.cuisine.unique():\n",
    "    # nb for cuisine\n",
    "    df_cuisine = df_data_2.loc[df_data_2['cuisine'] == cuisine]\n",
    "    recipe_count = df_cuisine.shape[0]\n",
    "    nb_recipe_to_add = max_recipe_count_per_cuisine - recipe_count\n",
    "    print(\"Got {0} value for {1}, need to add {2}\".format(recipe_count, cuisine, nb_recipe_to_add))\n",
    "    tmp_df = None\n",
    "    if nb_recipe_to_add != 0:\n",
    "        while nb_recipe_to_add != 0:\n",
    "            if nb_recipe_to_add >= recipe_count:\n",
    "                # Add the full dataframe\n",
    "                if tmp_df is None:\n",
    "                    tmp_df = df_cuisine\n",
    "                else:\n",
    "                    tmp_df = tmp_df.append(df_cuisine, ignore_index=True)\n",
    "                nb_recipe_to_add -= recipe_count\n",
    "            else:\n",
    "                # Only add a sample of it\n",
    "                if tmp_df is None:\n",
    "                    tmp_df = df_cuisine\n",
    "                else:\n",
    "                    tmp_df = tmp_df.append(df_cuisine.sample(nb_recipe_to_add), ignore_index=True)\n",
    "                nb_recipe_to_add = 0\n",
    "            # Add tmp df to df_data\n",
    "        df_data_2 = df_data_2.append(tmp_df, ignore_index=True)\n",
    "        print(\"Append a dataframe of {0} values\".format(tmp_df.shape[0]))\n",
    "        del(tmp_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dictionnary and create df_data_1 and df_test_1 from it\n",
    "output = {}\n",
    "for key, value in all_ingredients.items():\n",
    "    if value not in output:\n",
    "        output[value] = [key]\n",
    "    else:\n",
    "        output[value].append(key)\n",
    "#print(output)\n",
    "\n",
    "# Shuffle the data as well\n",
    "#df = df.sample(frac=1).reset_index(drop=True)\n",
    "df_data_3 = df_data_2.sample(frac=1).reset_index(drop=True)\n",
    "df_test_3 = df_test_2\n",
    "\n",
    "del(df_data_2)\n",
    "del(df_test_2)\n",
    "\n",
    "#print(output)\n",
    "to_remove = []\n",
    "for key, values in output.items():\n",
    "    for value in values:\n",
    "        if key < nb_min_value_after:\n",
    "            #print(\"Removing {0}\".format(value))\n",
    "            to_remove.append(value)\n",
    "df_data_3 = df_data_3.drop(columns=to_remove)\n",
    "df_test_3 = df_test_3.drop(columns=to_remove)\n",
    "\n",
    "#TODO multiply the training data by cuisine type as well\n",
    "\n",
    "display(df_data_3.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our training/validation datasets\n",
    "from sklearn import model_selection\n",
    "import sklearn\n",
    "\n",
    "# Name of the result column\n",
    "result_cols = ['cuisine']\n",
    "result_excl_cols = ['cuisine_']\n",
    "\n",
    "input_cols = [\n",
    "    ''\n",
    "]\n",
    "input_excl_cols = ['ingredients', 'cuisine']\n",
    "# Removing input_cols = ['store', 'item',\n",
    "# dom, cw, \n",
    "\n",
    "# Train on everything\n",
    "\n",
    "# Get the final values\n",
    "def get_values(df, cols=[], excl_cols = []):\n",
    "    columns = df.columns.values\n",
    "    # Remove all columns that are not inside the list\n",
    "    cols_to_drop = []\n",
    "    for column in columns:\n",
    "        find = False\n",
    "        ignore = False\n",
    "        for excl_col in excl_cols:\n",
    "            if column.startswith(excl_col):\n",
    "                ignore = True\n",
    "        if ignore is False:\n",
    "            for col in cols:\n",
    "                if column.startswith(col):\n",
    "                    find = True\n",
    "        if not find:\n",
    "            cols_to_drop.append(column)\n",
    "    print(\"dropping columns\")\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    print(\"end dropping columns\")\n",
    "    new_order = sorted(df.columns.values)\n",
    "    # Same order for both training and testing set\n",
    "    df = df[new_order]\n",
    "    return df.values\n",
    "\n",
    "df_data_4 = sklearn.utils.shuffle(df_data_3)\n",
    "\n",
    "X_train = get_values(df_data_4, input_cols, input_excl_cols)\n",
    "X_test = get_values(df_test_3, input_cols, input_excl_cols)\n",
    "\n",
    "Y_train = get_values(df_data_4, result_cols, result_excl_cols).ravel()\n",
    "\n",
    "# In test env, we calculate it for the test only\n",
    "if env == \"test\":\n",
    "    Y_test = get_values(df_test_1, result_cols, result_excl_cols).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "\n",
    "X_all = [x + y for x, y in zip(X_train, X_test)]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler() \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "# Def adding x_train + X_test + X_validation to fit all of them\n",
    "scaler.fit(X_all)  \n",
    "\n",
    "X_train = scaler.transform(X_train) \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to calculate the SMAPE\n",
    "def get_score(Y_validation, Y_validation_predict):\n",
    "    nb_success = 0\n",
    "    for i in range(0, len(Y_validation)):\n",
    "        if Y_validation[i] == Y_validation_predict[i]:\n",
    "            nb_success += 1\n",
    "    return nb_success / len(Y_validation) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import algorithm\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import *\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "models = []\n",
    "\n",
    "#models.append(('LogisticRegression', LogisticRegression()))\n",
    "#models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "#models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "#models.append(('GaussianNB', GaussianNB()))\n",
    "#models.append(('SVC', SVC()))\n",
    "\n",
    "for i in range(5, 5 + nb_models):\n",
    "    #models.append(('MLPClassifier_adamrelu_{0}'.format(i), MLPClassifier(hidden_layer_sizes=(i,), \n",
    "    #                                                            activation='relu', \n",
    "    #                                                            solver='adam',\n",
    "    #                                                            alpha=0.001, \n",
    "    #                                                            batch_size='auto',\n",
    "    #learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "    #random_state=i, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    #early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)))\n",
    "    \n",
    "    # Try multiple solutions\n",
    "    hidden_layers = (50, )\n",
    "    \n",
    "    models.append(('MLPClassifier_adamrelu_earlystopping_{0}'.format(i), MLPClassifier(hidden_layer_sizes=hidden_layers, \n",
    "                                                                activation='logistic', \n",
    "                                                                solver='adam',\n",
    "                                                                alpha=0.001, \n",
    "                                                                batch_size='auto',\n",
    "    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "    random_state=i, tol=0.00001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)))\n",
    "#models = []\n",
    "#models.append(('lgbm', lgbm.sklearn.LGBMRegressor()))\n",
    "# High value until first model get solved\n",
    "best_model = \"UNKNOWN\"\n",
    "\n",
    "res = []\n",
    "# Testing all models, one by one\n",
    "for name, model in models:\n",
    "    print(\"Executing for model {0}\".format(name))\n",
    "    time_start = datetime.now()\n",
    "\n",
    "    # Training the model\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Finish fit for {0}\".format(name))\n",
    "\n",
    "    Y_test_result = model.predict(X_test)\n",
    "    res.append(Y_test_result)\n",
    "    if env == \"test\":\n",
    "        # We can calculate the avg error\n",
    "        score = get_score(Y_test, Y_test_result)\n",
    "        print(\"Model {0} got score of {1}, time: {2}\".format(name, score, datetime.now() - time_start))\n",
    "    else:\n",
    "        # Let's write an output file, with the name of the model\n",
    "        print(\"Writing output file {0}.csv for model {0}\".format(name))\n",
    "        \n",
    "        df_test['cuisine'] = Y_test_result\n",
    "        result_df = df_test[['id', 'cuisine']]\n",
    "        result_df['cuisine'] = Y_test_result\n",
    "        \n",
    "        result_df.to_csv(\"{0}.csv\".format(name), index=False)\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all result in res, if test, display the result, if not, write it to a file\n",
    "final_res = []\n",
    "nb_variable = len(res[0])\n",
    "for variable in range(0, nb_variable):\n",
    "    final_res.append(0.0)\n",
    "    dict_cuisine = {}\n",
    "    for i in range(0, len(res)):\n",
    "        cuisine_found = res[i][variable]\n",
    "        if cuisine_found in dict_cuisine:\n",
    "            dict_cuisine[cuisine_found] += 1\n",
    "        else:\n",
    "            dict_cuisine[cuisine_found] = 1\n",
    "    # Now, we need to find the most common one for all the values inside dict_cuisine\n",
    "    current_value = 0\n",
    "    current_cuisine = \"\"\n",
    "    for cuisine in dict_cuisine:\n",
    "        if dict_cuisine[cuisine] > current_value:\n",
    "            current_cuisine = cuisine\n",
    "            current_value = dict_cuisine[cuisine]\n",
    "    \n",
    "    final_res[variable] = current_cuisine\n",
    "\n",
    "if env == \"test\":\n",
    "    # We can calculate the avg error\n",
    "    score = get_score(Y_test, final_res)\n",
    "    print(\"avg model got score of {0}\".format(score))\n",
    "else:\n",
    "    print(\"Writing output file merged.csv\".format(name))\n",
    "\n",
    "    df_test['cuisine'] = final_res\n",
    "    result_df = df_test[['id', 'cuisine']]\n",
    "    result_df['cuisine'] = final_res\n",
    "\n",
    "    result_df.to_csv(\"merged.csv\".format(name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
