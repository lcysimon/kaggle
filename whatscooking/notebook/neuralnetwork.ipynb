{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "from pandas import *\n",
    "import numpy\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize values\n",
    "\n",
    "env = None\n",
    "sample_size = None\n",
    "# Set env, if env = test, will only be run locally and display the result\n",
    "env = \"prod\"\n",
    "env = \"test\"\n",
    "\n",
    "nb_models = 10\n",
    "nb_min_value = 30\n",
    "\n",
    "# Number of value on which to train, if null, train on all value\n",
    "sample_size = None\n",
    "test_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_data contais cuisine        39774\n",
      "id             39774\n",
      "ingredients    39774\n",
      "dtype: int64 elements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...\n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...\n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35203</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17600</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  cuisine\n",
       "0  35203  italian\n",
       "1  17600  italian"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read training data + test data\n",
    "df_data_input = pandas.read_json(\"../input/train.json\")\n",
    "df_test_input = pandas.read_json(\"../input/test.json\")\n",
    "df_sample_input = pandas.read_csv(\"../input/sample_submission.csv\")\n",
    "\n",
    "print(\"df_data contais {0} elements\".format(df_data_input.count()))\n",
    "# Display basic information\n",
    "display(df_data_input.head(3))\n",
    "display(df_test_input.head(3))\n",
    "display(df_sample_input.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_data contais cuisine        38774\n",
      "id             38774\n",
      "ingredients    38774\n",
      "dtype: int64 elements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37231</th>\n",
       "      <td>brazilian</td>\n",
       "      <td>13802</td>\n",
       "      <td>[water, margarine, eggs, active dry yeast, bre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30430</th>\n",
       "      <td>italian</td>\n",
       "      <td>14311</td>\n",
       "      <td>[lasagna noodles, sauce, parmigiano reggiano c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19399</th>\n",
       "      <td>british</td>\n",
       "      <td>44867</td>\n",
       "      <td>[eggs, all-purpose flour, prepared horseradish...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cuisine     id                                        ingredients\n",
       "37231  brazilian  13802  [water, margarine, eggs, active dry yeast, bre...\n",
       "30430    italian  14311  [lasagna noodles, sauce, parmigiano reggiano c...\n",
       "19399    british  44867  [eggs, all-purpose flour, prepared horseradish..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if env == \"test\":\n",
    "    if sample_size is not None and sample_size > 0:\n",
    "        df_data = df_data_input.sample(sample_size)\n",
    "    else:\n",
    "        df_data = df_data_input\n",
    "    df_test = df_data_input.sample(test_size)\n",
    "    \n",
    "    # Removing all df_test from df_data to ensure not train with test data\n",
    "    df_common = df_data.merge(df_test,on=['id'])\n",
    "    #display(df_common)\n",
    "    df_data = df_data[(~df_data.id.isin(df_common.id))]\n",
    "else:\n",
    "    # set that to some default value\n",
    "    df_test = df_test_input\n",
    "    df_test['cuisine'] = \"todo\"\n",
    "    if sample_size is not None and sample_size > 0:\n",
    "        df_data = df_data_input.sample(sample_size)\n",
    "    else:\n",
    "        df_data = df_data_input\n",
    "        \n",
    "print(\"df_data contais {0} elements\".format(df_data.count()))\n",
    "# Display basic information\n",
    "display(df_data.head(3))\n",
    "display(df_test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value per cuisine = 7661\n",
      "Got 1149 value for greek, need to add 6512\n",
      "Append a dataframe of 6512 values\n",
      "Got 4200 value for southern_us, need to add 3461\n",
      "Append a dataframe of 4200 values\n",
      "Got 738 value for filipino, need to add 6923\n",
      "Append a dataframe of 6923 values\n",
      "Got 2922 value for indian, need to add 4739\n",
      "Append a dataframe of 4739 values\n",
      "Got 513 value for jamaican, need to add 7148\n",
      "Append a dataframe of 7148 values\n",
      "Got 964 value for spanish, need to add 6697\n",
      "Append a dataframe of 6697 values\n",
      "Got 7661 value for italian, need to add 0\n",
      "Got 6293 value for mexican, need to add 1368\n",
      "Append a dataframe of 6293 values\n",
      "Got 2590 value for chinese, need to add 5071\n",
      "Append a dataframe of 5071 values\n",
      "Got 787 value for british, need to add 6874\n",
      "Append a dataframe of 6874 values\n",
      "Got 1494 value for thai, need to add 6167\n",
      "Append a dataframe of 6167 values\n",
      "Got 804 value for vietnamese, need to add 6857\n",
      "Append a dataframe of 6857 values\n",
      "Got 1508 value for cajun_creole, need to add 6153\n",
      "Append a dataframe of 6153 values\n",
      "Got 456 value for brazilian, need to add 7205\n",
      "Append a dataframe of 7205 values\n",
      "Got 2580 value for french, need to add 5081\n",
      "Append a dataframe of 5081 values\n",
      "Got 1385 value for japanese, need to add 6276\n",
      "Append a dataframe of 6276 values\n",
      "Got 646 value for irish, need to add 7015\n",
      "Append a dataframe of 7015 values\n",
      "Got 813 value for korean, need to add 6848\n",
      "Append a dataframe of 6848 values\n",
      "Got 799 value for moroccan, need to add 6862\n",
      "Append a dataframe of 6862 values\n",
      "Got 472 value for russian, need to add 7189\n",
      "Append a dataframe of 7189 values\n"
     ]
    }
   ],
   "source": [
    "# Multiply the training data set for food where there is not that much data\n",
    "df_count = df_data.groupby('cuisine')['cuisine']\n",
    "max_recipe_count_per_cuisine = df_count.count().max()\n",
    "# Loop over all cuisine, if while < minimal, add this dataframe, then add a sample of those, to get exactly the same number\n",
    "\n",
    "print(\"Max value per cuisine = {0}\".format(max_recipe_count_per_cuisine))\n",
    "df_data_a = df_data\n",
    "for cuisine in df_data_a.cuisine.unique():\n",
    "    # nb for cuisine\n",
    "    df_cuisine = df_data_a.loc[df_data_a['cuisine'] == cuisine]\n",
    "    recipe_count = df_cuisine.shape[0]\n",
    "    nb_recipe_to_add = max_recipe_count_per_cuisine - recipe_count\n",
    "    print(\"Got {0} value for {1}, need to add {2}\".format(recipe_count, cuisine, nb_recipe_to_add))\n",
    "    tmp_df = None\n",
    "    if nb_recipe_to_add != 0:\n",
    "        while nb_recipe_to_add != 0:\n",
    "            if nb_recipe_to_add >= recipe_count:\n",
    "                # Add the full dataframe\n",
    "                if tmp_df is None:\n",
    "                    tmp_df = df_cuisine\n",
    "                else:\n",
    "                    tmp_df = tmp_df.append(df_cuisine, ignore_index=True)\n",
    "                nb_recipe_to_add -= recipe_count\n",
    "            else:\n",
    "                # Only add a sample of it\n",
    "                if tmp_df is None:\n",
    "                    tmp_df = df_cuisine\n",
    "                else:\n",
    "                    tmp_df = tmp_df.append(df_cuisine.sample(nb_recipe_to_add), ignore_index=True)\n",
    "                nb_recipe_to_add = 0\n",
    "            # Add tmp df to df_data\n",
    "        df_data_a = df_data_a.append(tmp_df, ignore_index=True)\n",
    "        print(\"Append a dataframe of {0} values\".format(tmp_df.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count1: 158884\n",
      "count2: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# Extract columns values of ingredients to multiple columns with boolean\n",
    "import re\n",
    "def preprocess_dataframe(df1, df2):\n",
    "    count1 = len(df1)\n",
    "    count2 = len(df2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"count1: {0}\".format(count1))\n",
    "    print(\"count2: {0}\".format(count2))\n",
    "    \n",
    "    total_df = df1.append(df2, ignore_index=True)\n",
    "    \n",
    "    d_list = []\n",
    "    \n",
    "    output = []\n",
    "    all_ingredients = {}\n",
    "    for index, row in total_df.iterrows():\n",
    "        for value_field in row['ingredients']:\n",
    "            # Transform the value to remove number and percentage\n",
    "            values = re.split('\\s+', value_field)\n",
    "            for value in values:\n",
    "                # build a dictionnary of all values\n",
    "                if value not in output:\n",
    "                    output.append(value)\n",
    "                    all_ingredients[value] = 1\n",
    "                else:\n",
    "                    all_ingredients[value] += 1\n",
    "                d_list.append({'id':row['id'], \n",
    "                               'value':value})\n",
    "\n",
    "    total_df = total_df.append(d_list, ignore_index=True)\n",
    "    total_df = total_df.groupby('id')['value'].value_counts()\n",
    "    total_df = total_df.unstack(level=-1).fillna(0)\n",
    "        \n",
    "    \n",
    "    # Then, we need to merge df_1 and df_2 with their id\n",
    "    df1 = df1.merge(total_df, left_on='id', right_on='id', how='inner')\n",
    "    df2 = df2.merge(total_df, left_on='id', right_on='id', how='inner')\n",
    "\n",
    "    # We do not need the ingredients column now, so, we can remove it\n",
    "    df1 = df1.drop(columns=['ingredients'])\n",
    "    df2 = df2.drop(columns=['ingredients'])\n",
    "\n",
    "    return df1, df2, all_ingredients\n",
    "\n",
    "df_data_0, df_test_0, all_ingredients = preprocess_dataframe(df_data_a, df_test)\n",
    "\n",
    "\n",
    "\n",
    "def category_to_number(df):\n",
    "    df[\"code_cuisine\"] = df.cuisine.astype(\"category\").cat.codes\n",
    "    mapping = df[[\"cuisine\", \"code_cuisine\"]]\n",
    "    return df, mapping.drop_duplicates()\n",
    "\n",
    "#df_data_1, code_mapping = category_to_number(df_data_1)\n",
    "#df_test_1, empty = category_to_number(df_test_1)\n",
    "\n",
    "\n",
    "display(df_data_a.head(5))\n",
    "display(df_data_0.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dictionnary and create df_data_1 and df_test_1 from it\n",
    "output = {}\n",
    "for key, value in all_ingredients.items():\n",
    "    if value not in output:\n",
    "        output[value] = [key]\n",
    "    else:\n",
    "        output[value].append(key)\n",
    "#print(output)\n",
    "\n",
    "# Shuffle the data as well\n",
    "#df = df.sample(frac=1).reset_index(drop=True)\n",
    "df_data_1 = df_data_0.sample(frac=1).reset_index(drop=True)\n",
    "df_test_1 = df_test_0\n",
    "\n",
    "#print(output)\n",
    "to_remove = []\n",
    "for key, values in output.items():\n",
    "    for value in values:\n",
    "        if key < nb_min_value:\n",
    "            #print(\"Removing {0}\".format(value))\n",
    "            to_remove.append(value)\n",
    "df_data_1 = df_data_1.drop(columns=to_remove)\n",
    "df_test_1 = df_test_1.drop(columns=to_remove)\n",
    "\n",
    "#TODO multiply the training data by cuisine type as well\n",
    "\n",
    "display(df_data_1.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our training/validation datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Name of the result column\n",
    "result_cols = ['cuisine']\n",
    "result_excl_cols = ['cuisine_']\n",
    "\n",
    "input_cols = [\n",
    "    ''\n",
    "]\n",
    "input_excl_cols = ['ingredients', 'cuisine']\n",
    "# Removing input_cols = ['store', 'item',\n",
    "# dom, cw, \n",
    "\n",
    "# Train on everything\n",
    "\n",
    "# Get the final values\n",
    "def get_values(df, cols=[], excl_cols = []):\n",
    "    columns = df.columns.values\n",
    "    # Remove all columns that are not inside the list\n",
    "    cols_to_drop = []\n",
    "    for column in columns:\n",
    "        find = False\n",
    "        ignore = False\n",
    "        for excl_col in excl_cols:\n",
    "            if column.startswith(excl_col):\n",
    "                ignore = True\n",
    "        if ignore is False:\n",
    "            for col in cols:\n",
    "                if column.startswith(col):\n",
    "                    find = True\n",
    "        if not find:\n",
    "            cols_to_drop.append(column)\n",
    "    print(\"dropping columns\")\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    print(\"end dropping columns\")\n",
    "    new_order = sorted(df.columns.values)\n",
    "    # Same order for both training and testing set\n",
    "    df = df[new_order]\n",
    "    return df.values\n",
    "\n",
    "X_train = get_values(df_data_1, input_cols, input_excl_cols)\n",
    "X_test = get_values(df_test_1, input_cols, input_excl_cols)\n",
    "\n",
    "Y_train = get_values(df_data_1, result_cols, result_excl_cols).ravel()\n",
    "\n",
    "# In test env, we calculate it for the test only\n",
    "if env == \"test\":\n",
    "    Y_test = get_values(df_test_1, result_cols, result_excl_cols).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "\n",
    "X_all = [x + y for x, y in zip(X_train, X_test)]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler() \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "# Def adding x_train + X_test + X_validation to fit all of them\n",
    "scaler.fit(X_all)  \n",
    "\n",
    "X_train = scaler.transform(X_train) \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to calculate the SMAPE\n",
    "def get_score(Y_validation, Y_validation_predict):\n",
    "    nb_success = 0\n",
    "    for i in range(0, len(Y_validation)):\n",
    "        if Y_validation[i] == Y_validation_predict[i]:\n",
    "            nb_success += 1\n",
    "    return nb_success / len(Y_validation) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import algorithm\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import *\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "models = []\n",
    "\n",
    "#models.append(('LogisticRegression', LogisticRegression()))\n",
    "#models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "#models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "#models.append(('GaussianNB', GaussianNB()))\n",
    "#models.append(('SVC', SVC()))\n",
    "\n",
    "for i in range(5, 5 + nb_models):\n",
    "    #models.append(('MLPClassifier_adamrelu_{0}'.format(i), MLPClassifier(hidden_layer_sizes=(i,), \n",
    "    #                                                            activation='relu', \n",
    "    #                                                            solver='adam',\n",
    "    #                                                            alpha=0.001, \n",
    "    #                                                            batch_size='auto',\n",
    "    #learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "    #random_state=i, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    #early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)))\n",
    "    \n",
    "    # Try multiple solutions\n",
    "    hidden_layers = (50, )\n",
    "    \n",
    "    models.append(('MLPClassifier_adamrelu_earlystopping_{0}'.format(i), MLPClassifier(hidden_layer_sizes=hidden_layers, \n",
    "                                                                activation='logistic', \n",
    "                                                                solver='adam',\n",
    "                                                                alpha=0.001, \n",
    "                                                                batch_size='auto',\n",
    "    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "    random_state=i, tol=0.00001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)))\n",
    "#models = []\n",
    "#models.append(('lgbm', lgbm.sklearn.LGBMRegressor()))\n",
    "# High value until first model get solved\n",
    "best_model = \"UNKNOWN\"\n",
    "\n",
    "res = []\n",
    "# Testing all models, one by one\n",
    "for name, model in models:\n",
    "    print(\"Executing for model {0}\".format(name))\n",
    "    time_start = datetime.now()\n",
    "\n",
    "    # Training the model\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Finish fit for {0}\".format(name))\n",
    "\n",
    "    Y_test_result = model.predict(X_test)\n",
    "    res.append(Y_test_result)\n",
    "    if env == \"test\":\n",
    "        # We can calculate the avg error\n",
    "        score = get_score(Y_test, Y_test_result)\n",
    "        print(\"Model {0} got score of {1}, time: {2}\".format(name, score, datetime.now() - time_start))\n",
    "    else:\n",
    "        # Let's write an output file, with the name of the model\n",
    "        print(\"Writing output file {0}.csv for model {0}\".format(name))\n",
    "        \n",
    "        df_test['cuisine'] = Y_test_result\n",
    "        result_df = df_test[['id', 'cuisine']]\n",
    "        result_df['cuisine'] = Y_test_result\n",
    "        \n",
    "        result_df.to_csv(\"{0}.csv\".format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all result in res, if test, display the result, if not, write it to a file\n",
    "final_res = []\n",
    "nb_variable = len(res[0])\n",
    "for variable in range(0, nb_variable):\n",
    "    final_res.append(0.0)\n",
    "    dict_cuisine = {}\n",
    "    for i in range(0, len(res)):\n",
    "        cuisine_found = res[i][variable]\n",
    "        if cuisine_found in dict_cuisine:\n",
    "            dict_cuisine[cuisine_found] += 1\n",
    "        else:\n",
    "            dict_cuisine[cuisine_found] = 1\n",
    "    # Now, we need to find the most common one for all the values inside dict_cuisine\n",
    "    current_value = 0\n",
    "    current_cuisine = \"\"\n",
    "    for cuisine in dict_cuisine:\n",
    "        if dict_cuisine[cuisine] > current_value:\n",
    "            current_cuisine = cuisine\n",
    "            current_value = dict_cuisine[cuisine]\n",
    "    \n",
    "    final_res[variable] = current_cuisine\n",
    "\n",
    "if env == \"test\":\n",
    "    # We can calculate the avg error\n",
    "    score = get_score(Y_test, final_res)\n",
    "    print(\"avg model got score of {0}\".format(score))\n",
    "else:\n",
    "    print(\"Writing output file merged.csv\".format(name))\n",
    "\n",
    "    df_test['cuisine'] = final_res\n",
    "    result_df = df_test[['id', 'cuisine']]\n",
    "    result_df['cuisine'] = final_res\n",
    "\n",
    "    result_df.to_csv(\"merged.csv\".format(name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
